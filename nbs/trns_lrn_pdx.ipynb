{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer learning with PDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/vol/ml/apartin/projects/pdx-histo/nbs\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "fdir = Path.cwd()\n",
    "print(fdir)\n",
    "sys.path.append(str(fdir/'..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/37893755/tensorflow-set-cuda-visible-devices-within-jupyter\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "# %env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# https://www.codegrepper.com/code-examples/python/suppres+tensorflow+warnings\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "# os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "from collections import OrderedDict\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from pprint import pprint, pformat\n",
    "import shutil\n",
    "from time import time\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, BatchNormalization\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "import src\n",
    "from src.config import cfg\n",
    "from src.models import build_model_rsp, build_model_rsp_baseline, keras_callbacks, load_best_model\n",
    "from src.ml.scale import get_scaler\n",
    "from src.ml.evals import calc_scores, save_confusion_matrix\n",
    "from src.ml.keras_utils import plot_prfrm_metrics\n",
    "from src.utils.classlogger import Logger\n",
    "from src.utils.utils import (cast_list, create_outdir, create_outdir_2, dump_dict, fea_types_to_str_name,\n",
    "                             get_print_func, read_lines, Params, Timer)\n",
    "from src.datasets.tidy import split_data_and_extract_fea, extract_fea, TidyData\n",
    "from src.tf_utils import get_tfr_files\n",
    "from src.sf_utils import (create_manifest, create_tf_data, calc_class_weights,\n",
    "                          parse_tfrec_fn_rsp, parse_tfrec_fn_rna)\n",
    "from src.sf_utils import bold, green, blue, yellow, cyan, red\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataname=\"tidy_drug_pairs_all_samples\"\n",
    "prjname=\"bin_rsp_drug_pairs_all_samples\"\n",
    "id_name=\"smp\"\n",
    "target=\"Response\"\n",
    "split_on=\"Group\"\n",
    "n_samples=-1\n",
    "tfr_dir_name=\"PDX_FIXED_RSP_DRUG_PAIR_0.1_of_tiles\"\n",
    "trn_phase=\"train\"\n",
    "use_tile=True\n",
    "use_ge=True\n",
    "use_dd1=True\n",
    "use_dd2=True\n",
    "scale_fea=False\n",
    "\n",
    "print_fn = print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6962, 4950)\n"
     ]
    }
   ],
   "source": [
    "# Create project dir (if it doesn't exist)\n",
    "prjdir = cfg.MAIN_PRJDIR/prjname\n",
    "\n",
    "# fea_names = \"tile_dd1_dd2\"\n",
    "fea_names = \"tile_ge_dd1_dd2\"\n",
    "prm_file_path = fdir/f\"../default_params/default_params_{fea_names}.json\"\n",
    "params = Params(prm_file_path)\n",
    "\n",
    "# Load dataframe (annotations)\n",
    "annotations_file = cfg.DATA_PROCESSED_DIR/dataname/cfg.SF_ANNOTATIONS_FILENAME\n",
    "data = pd.read_csv(annotations_file)\n",
    "data = data.astype({\"image_id\": str, \"slide\": str})\n",
    "print(data.shape)\n",
    "\n",
    "# Determine tfr_dir (where TFRecords are stored)\n",
    "# if args.target[0] == \"Response\":\n",
    "#     if params.single_drug:\n",
    "#         tfr_dir = cfg.SF_TFR_DIR_RSP\n",
    "#     else:\n",
    "#         tfr_dir = (cfg.DATADIR/args.tfr_dir_name).resolve()\n",
    "# elif args.target[0] == \"ctype\":\n",
    "#     tfr_dir = cfg.SF_TFR_DIR_RNA_NEW\n",
    "\n",
    "tfr_dir = (cfg.DATADIR/tfr_dir_name).resolve()\n",
    "label = f\"{params.tile_px}px_{params.tile_um}um\"\n",
    "tfr_dir = tfr_dir/label\n",
    "\n",
    "# Scalers for each feature set\n",
    "ge_scaler, dd1_scaler, dd2_scaler = None, None, None\n",
    "\n",
    "ge_cols  = [c for c in data.columns if c.startswith(\"ge_\")]\n",
    "dd1_cols = [c for c in data.columns if c.startswith(\"dd1_\")]\n",
    "dd2_cols = [c for c in data.columns if c.startswith(\"dd2_\")]\n",
    "\n",
    "if scale_fea:\n",
    "    if use_ge and len(ge_cols) > 0:\n",
    "        ge_scaler = get_scaler(data[ge_cols])\n",
    "    if use_dd1 and len(dd1_cols) > 0:\n",
    "        dd1_scaler = get_scaler(data[dd1_cols])\n",
    "    if use_dd2 and len(dd2_cols) > 0:\n",
    "        dd2_scaler = get_scaler(data[dd2_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------\n",
    "# Data splits\n",
    "# -----------------------------------------------\n",
    "# if params.drug_specific is None:\n",
    "if use_dd1 is False and use_dd2 is False:\n",
    "    splitdir = cfg.DATADIR/\"PDX_Transfer_Learning_Classification/Processed_Data/Data_For_MultiModal_Learning/Data_Partition_Drug_Specific\"\n",
    "    splitdir = splitdir/params.drug_specific\n",
    "    split_id = 0\n",
    "else:\n",
    "    splitdir = cfg.DATADIR/\"PDX_Transfer_Learning_Classification/Processed_Data/Data_For_MultiModal_Learning/Data_Partition\"\n",
    "    split_id = 81\n",
    "    # split_id = 0\n",
    "\n",
    "tr_id = cast_list(read_lines(str(splitdir/f\"cv_{split_id}\"/\"TrainList.txt\")), int)\n",
    "vl_id = cast_list(read_lines(str(splitdir/f\"cv_{split_id}\"/\"ValList.txt\")), int)\n",
    "te_id = cast_list(read_lines(str(splitdir/f\"cv_{split_id}\"/\"TestList.txt\")), int)\n",
    "\n",
    "# Update ids\n",
    "index_col_name = \"index\"\n",
    "tr_id = sorted(set(data[index_col_name]).intersection(set(tr_id)))\n",
    "vl_id = sorted(set(data[index_col_name]).intersection(set(vl_id)))\n",
    "te_id = sorted(set(data[index_col_name]).intersection(set(te_id)))\n",
    "\n",
    "# Subsample train samples\n",
    "if n_samples > 0:\n",
    "    if n_samples < len(tr_id):\n",
    "        tr_id = tr_id[:n_samples]\n",
    "    if n_samples < len(vl_id):\n",
    "        vl_id = vl_id[:n_samples]\n",
    "    if n_samples < len(te_id):\n",
    "        te_id = te_id[:n_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train samples 5574 (80.06%)\n",
      "Val   samples 690 (9.91%)\n",
      "Test  samples 698 (10.03%)\n",
      "\n",
      "Total intersects on Group btw tr and vl: 0\n",
      "Total intersects on Group btw tr and te: 0\n",
      "Total intersects on Group btw vl and te: 0\n",
      "Unique Group in tr: 760\n",
      "Unique Group in vl: 97\n",
      "Unique Group in te: 102\n",
      "Total samples 6962\n",
      "\n",
      "These samples miss a tfrecord:\n",
      "Empty DataFrame\n",
      "Columns: [smp, image_id]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# --------------\n",
    "# w/o TidyData\n",
    "# --------------\n",
    "kwargs = {\"ge_cols\": ge_cols,\n",
    "          \"dd1_cols\": dd1_cols,\n",
    "          \"dd2_cols\": dd2_cols,\n",
    "          \"ge_scaler\": ge_scaler,\n",
    "          \"dd1_scaler\": dd1_scaler,\n",
    "          \"dd2_scaler\": dd2_scaler,\n",
    "          \"ge_dtype\": cfg.GE_DTYPE,\n",
    "          \"dd_dtype\": cfg.DD_DTYPE,\n",
    "          \"index_col_name\": index_col_name,\n",
    "          \"split_on\": split_on\n",
    "          }\n",
    "tr_ge, tr_dd1, tr_dd2, tr_meta = split_data_and_extract_fea(data, ids=tr_id, **kwargs)\n",
    "vl_ge, vl_dd1, vl_dd2, vl_meta = split_data_and_extract_fea(data, ids=vl_id, **kwargs)\n",
    "te_ge, te_dd1, te_dd2, te_meta = split_data_and_extract_fea(data, ids=te_id, **kwargs)\n",
    "\n",
    "ge_shape = (tr_ge.shape[1],)\n",
    "dd_shape = (tr_dd1.shape[1],)\n",
    "\n",
    "# Make sure indices do not overlap\n",
    "assert len( set(tr_id).intersection(set(vl_id)) ) == 0, \"Overlapping indices btw tr and vl\"\n",
    "assert len( set(tr_id).intersection(set(te_id)) ) == 0, \"Overlapping indices btw tr and te\"\n",
    "assert len( set(vl_id).intersection(set(te_id)) ) == 0, \"Overlapping indices btw vl and te\"\n",
    "\n",
    "# Print split ratios\n",
    "print_fn(\"\")\n",
    "print_fn(\"Train samples {} ({:.2f}%)\".format( len(tr_id), 100*len(tr_id)/data.shape[0] ))\n",
    "print_fn(\"Val   samples {} ({:.2f}%)\".format( len(vl_id), 100*len(vl_id)/data.shape[0] ))\n",
    "print_fn(\"Test  samples {} ({:.2f}%)\".format( len(te_id), 100*len(te_id)/data.shape[0] ))\n",
    "\n",
    "tr_grp_unq = set(tr_meta[split_on].values)\n",
    "vl_grp_unq = set(vl_meta[split_on].values)\n",
    "te_grp_unq = set(te_meta[split_on].values)\n",
    "print_fn(\"\")\n",
    "print_fn(f\"Total intersects on {split_on} btw tr and vl: {len(tr_grp_unq.intersection(vl_grp_unq))}\")\n",
    "print_fn(f\"Total intersects on {split_on} btw tr and te: {len(tr_grp_unq.intersection(te_grp_unq))}\")\n",
    "print_fn(f\"Total intersects on {split_on} btw vl and te: {len(vl_grp_unq.intersection(te_grp_unq))}\")\n",
    "print_fn(f\"Unique {split_on} in tr: {len(tr_grp_unq)}\")\n",
    "print_fn(f\"Unique {split_on} in vl: {len(vl_grp_unq)}\")\n",
    "print_fn(f\"Unique {split_on} in te: {len(te_grp_unq)}\")\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Obtain T/V/E tfr filenames\n",
    "# --------------------------\n",
    "# List of sample names for T/V/E\n",
    "tr_smp_names = list(tr_meta[id_name].values)\n",
    "vl_smp_names = list(vl_meta[id_name].values)\n",
    "te_smp_names = list(te_meta[id_name].values)\n",
    "\n",
    "# TFRecords filenames\n",
    "train_tfr_files = get_tfr_files(tfr_dir, tr_smp_names)\n",
    "val_tfr_files = get_tfr_files(tfr_dir, vl_smp_names)\n",
    "test_tfr_files = get_tfr_files(tfr_dir, te_smp_names)\n",
    "print(\"Total samples {}\".format(len(train_tfr_files) + len(val_tfr_files) + len(test_tfr_files)))\n",
    "\n",
    "# Missing tfrecords\n",
    "print(\"\\nThese samples miss a tfrecord:\")\n",
    "df_miss = data.loc[~data[id_name].isin(tr_smp_names + vl_smp_names + te_smp_names), [\"smp\", \"image_id\"]]\n",
    "print(df_miss)\n",
    "\n",
    "assert sorted(tr_smp_names) == sorted(tr_meta[id_name].values.tolist()), \"Sample names in the tr_smp_names and tr_meta don't match.\"\n",
    "assert sorted(vl_smp_names) == sorted(vl_meta[id_name].values.tolist()), \"Sample names in the vl_smp_names and vl_meta don't match.\"\n",
    "assert sorted(te_smp_names) == sorted(te_meta[id_name].values.tolist()), \"Sample names in the te_smp_names and te_meta don't match.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'num_samples': 5309, 'num_tiles': 201000}, 1: {'num_samples': 265, 'num_tiles': 11422}}\n",
      "{0: 0.5284129353233831, 1: 9.29880931535633}\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Class weight\n",
    "# -------------------------------\n",
    "tile_cnts = pd.read_csv(tfr_dir/\"tile_counts_per_slide.csv\")\n",
    "tile_cnts.insert(loc=0, column=\"tfr_abs_fname\", value=tile_cnts[\"tfr_fname\"].map(lambda s: str(tfr_dir/s)))\n",
    "cat = tile_cnts[tile_cnts[\"tfr_abs_fname\"].isin(train_tfr_files)]\n",
    "cat = cat.groupby(target).agg({\"smp\": \"nunique\", \"max_tiles\": \"sum\", \"n_tiles\": \"sum\", \"slide\": \"nunique\"}).reset_index()\n",
    "categories = {}\n",
    "for i, row_data in cat.iterrows():\n",
    "    dct = {\"num_samples\": row_data[\"smp\"], \"num_tiles\": row_data[\"n_tiles\"]}\n",
    "    categories[row_data[target]] = dct\n",
    "\n",
    "class_weight = calc_class_weights(train_tfr_files,\n",
    "                                  class_weights_method=params.class_weights_method,\n",
    "                                  categories=categories)\n",
    "print(categories)\n",
    "print(class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating TF datasets.\n",
      "WARNING:tensorflow:AutoGraph could not transform <function parse_tfrec_fn_rsp at 0x7f3a6f7de3b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function parse_tfrec_fn_rsp at 0x7f3a6f7de3b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "\n",
      "Item 0\n",
      "\ttile_image: (64, 299, 299, 3)\n",
      "\tge_data: (64, 942)\n",
      "\tdd1_data: (64, 1993)\n",
      "\tdd2_data: (64, 1993)\n",
      "\n",
      "Item 1\n",
      "tf.Tensor(\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], shape=(64,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Parsing funcs\n",
    "# -------------------------------\n",
    "if target == \"Response\":\n",
    "    # Response\n",
    "    parse_fn = parse_tfrec_fn_rsp\n",
    "    parse_fn_train_kwargs = {\n",
    "        \"use_tile\": use_tile,\n",
    "        \"use_ge\": use_ge,\n",
    "        \"use_dd1\": use_dd1,\n",
    "        \"use_dd2\": use_dd2,\n",
    "        \"ge_scaler\": ge_scaler,\n",
    "        \"dd1_scaler\": dd1_scaler,\n",
    "        \"dd2_scaler\": dd2_scaler,\n",
    "        \"id_name\": id_name,\n",
    "        \"augment\": params.augment,\n",
    "        \"application\": params.base_image_model,\n",
    "    }\n",
    "else:\n",
    "    # Ctype\n",
    "    parse_fn = parse_tfrec_fn_rna\n",
    "    parse_fn_train_kwargs = {\n",
    "        'use_tile': use_tile,\n",
    "        'use_ge': use_ge,\n",
    "        'ge_scaler': ge_scaler,\n",
    "        'id_name': id_name,\n",
    "        'MODEL_TYPE': params.model_type,\n",
    "        'AUGMENT': params.augment,\n",
    "    }\n",
    "\n",
    "parse_fn_non_train_kwargs = parse_fn_train_kwargs.copy()\n",
    "parse_fn_non_train_kwargs[\"augment\"] = False\n",
    "\n",
    "\n",
    "# ----------------------------------------\n",
    "# Number of tiles/examples in each dataset\n",
    "# ----------------------------------------\n",
    "# import ipdb; ipdb.set_trace()\n",
    "tr_tiles = tile_cnts[tile_cnts[id_name].isin(tr_smp_names)][\"n_tiles\"].sum()\n",
    "vl_tiles = tile_cnts[tile_cnts[id_name].isin(vl_smp_names)][\"n_tiles\"].sum()\n",
    "te_tiles = tile_cnts[tile_cnts[id_name].isin(te_smp_names)][\"n_tiles\"].sum()\n",
    "\n",
    "eval_batch_size = 8 * params.batch_size\n",
    "tr_steps = tr_tiles // params.batch_size\n",
    "vl_steps = vl_tiles // eval_batch_size\n",
    "te_steps = te_tiles // eval_batch_size\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Create TF datasets\n",
    "# -------------------------------\n",
    "print(\"\\nCreating TF datasets.\")\n",
    "\n",
    "# Training\n",
    "# import ipdb; ipdb.set_trace()\n",
    "train_data = create_tf_data(\n",
    "    batch_size=params.batch_size,\n",
    "    deterministic=False,\n",
    "    include_meta=False,\n",
    "    interleave=True,\n",
    "    n_concurrent_shards=params.n_concurrent_shards,  # 32, 64\n",
    "    parse_fn=parse_fn,\n",
    "    prefetch=1,  # 2\n",
    "    repeat=True,\n",
    "    seed=None,  # cfg.seed,\n",
    "    shuffle_files=True,\n",
    "    shuffle_size=params.shuffle_size,  # 8192\n",
    "    tfrecords=train_tfr_files,\n",
    "    **parse_fn_train_kwargs)\n",
    "\n",
    "# Determine feature shapes from data\n",
    "bb = next(train_data.__iter__())\n",
    "\n",
    "# Infer dims of features from the data\n",
    "# import ipdb; ipdb.set_trace()\n",
    "if use_ge:\n",
    "    ge_shape = bb[0][\"ge_data\"].numpy().shape[1:]\n",
    "else:\n",
    "    ge_shape = None\n",
    "\n",
    "if use_dd1:\n",
    "    dd_shape = bb[0][\"dd1_data\"].numpy().shape[1:]\n",
    "else:\n",
    "    dd_shape = None\n",
    "\n",
    "# Print keys and dims\n",
    "for i, item in enumerate(bb):\n",
    "    print(f\"\\nItem {i}\")\n",
    "    if isinstance(item, dict):\n",
    "        for k in item.keys():\n",
    "            print(f\"\\t{k}: {item[k].numpy().shape}\")\n",
    "    elif isinstance(item.numpy(), np.ndarray):\n",
    "        print(item)\n",
    "\n",
    "# for i, rec in enumerate(train_data.take(2)):\n",
    "#     tf.print(rec[1])\n",
    "\n",
    "# Evaluation (val, test, train)\n",
    "create_tf_data_eval_kwargs = {\n",
    "    \"batch_size\": eval_batch_size,\n",
    "    \"include_meta\": False,\n",
    "    \"interleave\": False,\n",
    "    \"parse_fn\": parse_fn,\n",
    "    \"prefetch\": None,  # 2\n",
    "    \"repeat\": False,\n",
    "    \"seed\": None,\n",
    "    \"shuffle_files\": False,\n",
    "    \"shuffle_size\": None,\n",
    "}\n",
    "\n",
    "create_tf_data_eval_kwargs.update({\"tfrecords\": val_tfr_files, \"include_meta\": False})\n",
    "val_data = create_tf_data(\n",
    "    **create_tf_data_eval_kwargs,\n",
    "    **parse_fn_non_train_kwargs\n",
    ")\n",
    "\n",
    "create_tf_data_eval_kwargs.update({\"tfrecords\": test_tfr_files, \"include_meta\": True})\n",
    "test_data = create_tf_data(\n",
    "    **create_tf_data_eval_kwargs,\n",
    "    **parse_fn_non_train_kwargs\n",
    ")\n",
    "\n",
    "create_tf_data_eval_kwargs.update({\"tfrecords\": val_tfr_files, \"include_meta\": True})\n",
    "eval_val_data = create_tf_data(\n",
    "    **create_tf_data_eval_kwargs,\n",
    "    **parse_fn_non_train_kwargs\n",
    ")\n",
    "\n",
    "create_tf_data_eval_kwargs.update({\"tfrecords\": train_tfr_files, \"include_meta\": True})\n",
    "eval_train_data = create_tf_data(\n",
    "    **create_tf_data_eval_kwargs,\n",
    "    **parse_fn_non_train_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: GeForce RTX 2080 Ti, compute capability 7.5\n"
     ]
    }
   ],
   "source": [
    "# Mixed precision\n",
    "if params.use_fp16:\n",
    "    if int(tf.keras.__version__.split(\".\")[1]) == 4:  # TF 2.4\n",
    "        from tensorflow.keras import mixed_precision\n",
    "        policy = mixed_precision.Policy(\"mixed_float16\")\n",
    "        mixed_precision.set_global_policy(policy)\n",
    "    elif int(tf.keras.__version__.split(\".\")[1]) == 3:  # TF 2.3\n",
    "        from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "        policy = mixed_precision.Policy(\"mixed_float16\")\n",
    "        mixed_precision.set_policy(policy)\n",
    "        \n",
    "# Target\n",
    "loss = losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples:\n",
      "    Total: 212422\n",
      "    Positive: 11422 (5.38% of total)\n",
      "\n",
      "Output bias: [-2.86776359]\n"
     ]
    }
   ],
   "source": [
    "# Calc output bias\n",
    "if use_tile:\n",
    "    # from sf_utils import get_categories_from_manifest\n",
    "    # categories = get_categories_from_manifest(train_tfr_files, manifest, outcomes)\n",
    "    neg = categories[0][\"num_tiles\"]\n",
    "    pos = categories[1][\"num_tiles\"]\n",
    "else:\n",
    "    neg, pos = np.bincount(tr_meta[args.target[0]].values)\n",
    "\n",
    "total = neg + pos\n",
    "print_fn(\"Samples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n\".format(total, pos, 100 * pos / total))\n",
    "output_bias = np.log([pos/neg])\n",
    "print_fn(f\"Output bias: {output_bias}\")\n",
    "# output_bias = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # bb = train_data.take(1)\n",
    "# bb = next(eval_train_data.__iter__())\n",
    "# print(len(bb))\n",
    "# print(bb[0].keys())\n",
    "# print(len(bb[1]))\n",
    "# print(bb[2].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for xdata, labels, meta in eval_train_data.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        # plt.imshow(xdata[\"tile_image\"][i].numpy().astype(\"uint8\"))\n",
    "        plt.imshow(xdata[\"tile_image\"][i].numpy())\n",
    "        # plt.title(f\"{labels.numpy()[i]}; {meta['tile_id'].numpy()[i]}; {meta['image_id'].numpy()[i]}; {meta['ctype'].numpy()[i]}\")\n",
    "        plt.title(f\"{labels.numpy()[i]}\")\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20, 20))\n",
    "# for xdata, labels, meta in eval_train_data.take(1):\n",
    "#     for i in range(9):\n",
    "#         ax = plt.subplot(3, 3, i + 1)\n",
    "#         plt.imshow(xdata[\"tile_image\"][i].numpy()) # .astype(\"uint8\"))\n",
    "#         plt.title(\"{}; slide: {}; tile: {}; trt; {}\".format(labels.numpy()[i],\n",
    "#                                                             meta['image_id'].numpy()[i].decode(\"utf-8\"),\n",
    "#                                                             meta['tile_id'].numpy()[i].decode(\"utf-8\"),\n",
    "#                                                             meta['trt'].numpy()[i].decode(\"utf-8\")))\n",
    "#         plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33830264\n",
      "0.35412648\n",
      "-1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "x = xdata[\"tile_image\"][i].numpy()\n",
    "print(x.mean())\n",
    "print(x.std())\n",
    "print(x.min())\n",
    "print(x.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = []\n",
    "monitor = \"val_loss\"\n",
    "patience = 7\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor=monitor,\n",
    "                              factor=0.5,\n",
    "                              patience=5,\n",
    "                              verbose=1,\n",
    "                              mode=\"auto\",\n",
    "                              min_delta=0.0001,\n",
    "                              cooldown=0,\n",
    "                              min_lr=0)\n",
    "callbacks.append(reduce_lr)\n",
    "\n",
    "early_stop = EarlyStopping(monitor=monitor,\n",
    "                           patience=patience,\n",
    "                           mode=\"auto\",\n",
    "                           restore_best_weights=True,\n",
    "                           verbose=1)\n",
    "callbacks.append(early_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense1_dd1 = params.dense1_dd1\n",
    "dense1_dd2 = params.dense1_dd2\n",
    "dense1_ge = params.dense1_ge\n",
    "dense1_img = params.dense1_img\n",
    "dense2_img = params.dense2_img\n",
    "dense1_top = params.dense1_top\n",
    "learning_rate = params.learning_rate\n",
    "dropout1_top = params.dropout1_top\n",
    "\n",
    "pretrain = \"imagenet\"\n",
    "pooling = \"avg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if output_bias is not None:\n",
    "#     output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "\n",
    "# model_inputs = []\n",
    "# merge_inputs = []\n",
    "\n",
    "# if use_tile:\n",
    "#     image_shape = (cfg.IMAGE_SIZE, cfg.IMAGE_SIZE, 3)\n",
    "#     tile_input_tensor = tf.keras.Input(shape=image_shape, name=\"tile_image\")\n",
    "#     base_img_model = tf.keras.applications.Xception(\n",
    "#         include_top=False,\n",
    "#         weights=pretrain,\n",
    "#         input_shape=None,\n",
    "#         input_tensor=None,\n",
    "#         pooling=pooling)\n",
    "\n",
    "#     # import ipdb; ipdb.set_trace()\n",
    "#     # print(len(base_img_model.trainable_weights))\n",
    "#     # print(len(base_img_model.non_trainable_weights))\n",
    "#     # print(len(base_img_model.layers))\n",
    "#     # base_img_model.trainable = False\n",
    "#     # x_tile = keras.layers.GlobalAveragePooling2D()(tile_input_tensor)\n",
    "\n",
    "#     x_tile = base_img_model(tile_input_tensor)\n",
    "#     model_inputs.append(tile_input_tensor)\n",
    "\n",
    "#     if dense1_img > 0:\n",
    "#         x_tile = Dense(dense1_img, activation=tf.nn.relu, name=\"dense1_img\")(x_tile)\n",
    "#         # x_tile = BatchNormalization(name=\"batchnorm_im\")(x_tile)\n",
    "#     if dense2_img > 0:\n",
    "#         x_tile = Dense(dense2_img, activation=tf.nn.relu, name=\"dense2_img\")(x_tile)\n",
    "#     if (dense1_img > 0) or (dense2_img > 0):\n",
    "#         x_tile = BatchNormalization(name=\"batchnorm_im\")(x_tile)\n",
    "#     merge_inputs.append(x_tile)\n",
    "#     del tile_input_tensor, x_tile\n",
    "\n",
    "# if use_ge:\n",
    "#     ge_input_tensor = tf.keras.Input(shape=ge_shape, name=\"ge_data\")\n",
    "#     x_ge = Dense(dense1_ge, activation=tf.nn.relu, name=\"dense1_ge\")(ge_input_tensor)\n",
    "#     x_ge = BatchNormalization(name=\"batchnorm_ge\")(x_ge)\n",
    "#     # x_ge = Dropout(0.4)(x_ge)\n",
    "#     model_inputs.append(ge_input_tensor)\n",
    "#     merge_inputs.append(x_ge)\n",
    "#     del ge_input_tensor, x_ge\n",
    "\n",
    "# if use_dd1:\n",
    "#     dd1_input_tensor = tf.keras.Input(shape=dd_shape, name=\"dd1_data\")\n",
    "#     x_dd1 = Dense(dense1_dd1, activation=tf.nn.relu, name=\"dense1_dd1\")(dd1_input_tensor)\n",
    "#     x_dd1 = BatchNormalization(name=\"batchnorm_dd1\")(x_dd1)\n",
    "#     # x_dd1 = Dropout(0.4)(x_dd1)\n",
    "#     model_inputs.append(dd1_input_tensor)\n",
    "#     merge_inputs.append(x_dd1)\n",
    "#     del dd1_input_tensor, x_dd1\n",
    "\n",
    "# if use_dd2:\n",
    "#     dd2_input_tensor = tf.keras.Input(shape=dd_shape, name=\"dd2_data\")\n",
    "#     x_dd2 = Dense(dense1_dd2, activation=tf.nn.relu, name=\"dense1_dd2\")(dd2_input_tensor)\n",
    "#     x_dd2 = BatchNormalization(name=\"batchnorm_dd2\")(x_dd2)\n",
    "#     # x_dd2 = Dropout(0.4)(x_dd2)\n",
    "#     model_inputs.append(dd2_input_tensor)\n",
    "#     merge_inputs.append(x_dd2)\n",
    "#     del dd2_input_tensor, x_dd2\n",
    "\n",
    "# # Merge towers\n",
    "# merged_model = layers.Concatenate(axis=1, name=\"merger\")(merge_inputs)\n",
    "\n",
    "# merged_model = tf.keras.layers.Dense(dense1_top, activation=tf.nn.relu,\n",
    "#                                      name=\"dense1_top\", kernel_regularizer=None)(merged_model)\n",
    "# merged_model = BatchNormalization(name=\"batchnorm_top\")(merged_model)\n",
    "# if dropout1_top > 0:\n",
    "#     merged_model = Dropout(dropout1_top)(merged_model)\n",
    "\n",
    "# softmax_output = tf.keras.layers.Dense(\n",
    "#     1, activation=\"sigmoid\", bias_initializer=output_bias, name=\"Response\")(merged_model)\n",
    "\n",
    "# # Assemble final model\n",
    "# model = tf.keras.Model(inputs=model_inputs, outputs=softmax_output)\n",
    "\n",
    "# metrics = [\n",
    "#       keras.metrics.AUC(name=\"roc-auc\", curve=\"ROC\"),\n",
    "#       keras.metrics.AUC(name=\"pr-auc\", curve=\"PR\"),\n",
    "# ]\n",
    "# if optimizer == \"SGD\":\n",
    "#     optimizer = optimizers.SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
    "# elif optimizer == \"Adam\":\n",
    "#     optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "# model.compile(loss=loss, optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_verbose = 1\n",
    "\n",
    "# print_fn(f\"Train steps:      {tr_steps}\")\n",
    "# print_fn(f\"Validation steps: {vl_steps}\")\n",
    "\n",
    "# history = model.fit(x=train_data,\n",
    "#                     validation_data=val_data,\n",
    "#                     steps_per_epoch=tr_steps,\n",
    "#                     validation_steps=vl_steps,\n",
    "#                     class_weight=class_weight,\n",
    "#                     epochs=params.epochs,\n",
    "#                     verbose=fit_verbose,\n",
    "#                     callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if output_bias is not None:\n",
    "    output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "\n",
    "model_inputs = []\n",
    "merge_inputs = []\n",
    "\n",
    "# Image\n",
    "image_shape = (cfg.IMAGE_SIZE, cfg.IMAGE_SIZE, 3)\n",
    "tile_input_tensor = tf.keras.Input(shape=image_shape, name=\"tile_image\")\n",
    "base_img_model = tf.keras.applications.Xception(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=None,\n",
    "    input_tensor=None,\n",
    "    pooling=\"avg\")\n",
    "base_img_model.trainable = False  # freeze weights\n",
    "\n",
    "x_tile = base_img_model(tile_input_tensor, training=False)\n",
    "model_inputs.append(tile_input_tensor)\n",
    "\n",
    "x_tile = Dense(dense1_img, activation=tf.nn.relu, name=\"dense1_img\")(x_tile)\n",
    "x_tile = Dense(dense2_img, activation=tf.nn.relu, name=\"dense2_img\")(x_tile)\n",
    "merge_inputs.append(x_tile)\n",
    "del tile_input_tensor, x_tile\n",
    "\n",
    "# GE\n",
    "ge_input_tensor = tf.keras.Input(shape=ge_shape, name=\"ge_data\")\n",
    "x_ge = Dense(dense1_ge, activation=tf.nn.relu, name=\"dense1_ge\")(ge_input_tensor)\n",
    "x_ge = BatchNormalization(name=\"batchnorm_ge\")(x_ge)\n",
    "model_inputs.append(ge_input_tensor)\n",
    "merge_inputs.append(x_ge)\n",
    "del ge_input_tensor, x_ge\n",
    "\n",
    "# DD1\n",
    "dd1_input_tensor = tf.keras.Input(shape=dd_shape, name=\"dd1_data\")\n",
    "x_dd1 = Dense(dense1_dd1, activation=tf.nn.relu, name=\"dense1_dd1\")(dd1_input_tensor)\n",
    "x_dd1 = BatchNormalization(name=\"batchnorm_dd1\")(x_dd1)\n",
    "model_inputs.append(dd1_input_tensor)\n",
    "merge_inputs.append(x_dd1)\n",
    "del dd1_input_tensor, x_dd1\n",
    "\n",
    "# DD2\n",
    "dd2_input_tensor = tf.keras.Input(shape=dd_shape, name=\"dd2_data\")\n",
    "x_dd2 = Dense(dense1_dd2, activation=tf.nn.relu, name=\"dense1_dd2\")(dd2_input_tensor)\n",
    "x_dd2 = BatchNormalization(name=\"batchnorm_dd2\")(x_dd2)\n",
    "model_inputs.append(dd2_input_tensor)\n",
    "merge_inputs.append(x_dd2)\n",
    "del dd2_input_tensor, x_dd2\n",
    "\n",
    "# Merge towers\n",
    "merged_model = layers.Concatenate(axis=1, name=\"merger\")(merge_inputs)\n",
    "\n",
    "# Dense layers of the top classfier\n",
    "merged_model = tf.keras.layers.Dense(dense1_top, activation=tf.nn.relu,\n",
    "                                     name=\"dense1_top\", kernel_regularizer=None)(merged_model)\n",
    "merged_model = Dropout(0.2)(merged_model)\n",
    "\n",
    "# Output\n",
    "softmax_output = tf.keras.layers.Dense(\n",
    "    1, activation=\"sigmoid\", bias_initializer=output_bias, name=\"Response\")(merged_model)\n",
    "\n",
    "# Assemble final model\n",
    "model = tf.keras.Model(inputs=model_inputs, outputs=softmax_output)\n",
    "\n",
    "metrics = [keras.metrics.AUC(name=\"roc-auc\", curve=\"ROC\"),\n",
    "           keras.metrics.AUC(name=\"pr-auc\", curve=\"PR\")\n",
    "]\n",
    "\n",
    "# optimizer = optimizers.SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
    "optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "tile_image (InputLayer)         [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "xception (Functional)           (None, 2048)         20861480    tile_image[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "ge_data (InputLayer)            [(None, 942)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dd1_data (InputLayer)           [(None, 1993)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dd2_data (InputLayer)           [(None, 1993)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense1_img (Dense)              (None, 1024)         2098176     xception[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense1_ge (Dense)               (None, 500)          471500      ge_data[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense1_dd1 (Dense)              (None, 250)          498500      dd1_data[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense1_dd2 (Dense)              (None, 250)          498500      dd2_data[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense2_img (Dense)              (None, 512)          524800      dense1_img[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batchnorm_ge (BatchNormalizatio (None, 500)          2000        dense1_ge[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batchnorm_dd1 (BatchNormalizati (None, 250)          1000        dense1_dd1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batchnorm_dd2 (BatchNormalizati (None, 250)          1000        dense1_dd2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merger (Concatenate)            (None, 1512)         0           dense2_img[0][0]                 \n",
      "                                                                 batchnorm_ge[0][0]               \n",
      "                                                                 batchnorm_dd1[0][0]              \n",
      "                                                                 batchnorm_dd2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense1_top (Dense)              (None, 500)          756500      merger[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 500)          0           dense1_top[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Response (Dense)                (None, 1)            501         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 25,713,957\n",
      "Trainable params: 4,850,477\n",
      "Non-trainable params: 20,863,480\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Base model.\n",
      "trainable_weights: 0\n",
      "non_trainable_weights: 234\n",
      "layers: 133\n",
      "output_shape: (None, 2048)\n",
      "trainable_variables: 0\n",
      "\n",
      "Full model.\n",
      "trainable_weights: 20\n",
      "non_trainable_weights: 240\n",
      "layers: 17\n",
      "output_shape: (None, 1)\n",
      "trainable_variables: 20\n"
     ]
    }
   ],
   "source": [
    "# Layers & models have three weight attributes:\n",
    "# weights: list of all weights variables of the layer.\n",
    "# trainable_weights: list of those that are meant to be updated (via gradient descent) to minimize the loss during training.\n",
    "# non_trainable_weights: list of those that aren't meant to be trained. Typically they are updated by the model during the forward pass.\n",
    "# In general, all weights are trainable weights. The only built-in layer that has non-trainable weights is the BatchNormalization layer. It uses non-trainable weights to keep track of the mean and variance of its inputs during training.\n",
    "print(\"\\nBase model.\")\n",
    "print(\"trainable_weights:\", len(base_img_model.trainable_weights))\n",
    "print(\"non_trainable_weights:\", len(base_img_model.non_trainable_weights))\n",
    "print(\"layers:\", len(base_img_model.layers))\n",
    "print(\"output_shape:\", base_img_model.output_shape)\n",
    "print(\"trainable_variables:\", len(base_img_model.trainable_variables))\n",
    "\n",
    "print(\"\\nFull model.\")\n",
    "print(\"trainable_weights:\", len(model.trainable_weights))\n",
    "print(\"non_trainable_weights:\", len(model.non_trainable_weights))\n",
    "print(\"layers:\", len(model.layers))\n",
    "print(\"output_shape:\", model.output_shape)\n",
    "print(\"trainable_variables:\", len(model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 39s 739ms/step - loss: 0.2495 - roc-auc: 0.4352 - pr-auc: 0.0376\n",
      "Loss: 0.2432\n"
     ]
    }
   ],
   "source": [
    "# initial_epochs = 10\n",
    "initial_epochs = 4\n",
    "# initial_epochs = 50\n",
    "\n",
    "res = model.evaluate(val_data, steps=vl_steps, verbose=1)\n",
    "print(\"Loss: {:0.4f}\".format(res[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train steps:      3319\n",
      "Validation steps: 47\n",
      "Epoch 1/4\n",
      "3319/3319 [==============================] - 567s 166ms/step - loss: 0.1930 - roc-auc: 0.9818 - pr-auc: 0.7267 - val_loss: 0.2390 - val_roc-auc: 0.9028 - val_pr-auc: 0.2021\n",
      "Epoch 2/4\n",
      "3319/3319 [==============================] - 550s 166ms/step - loss: 0.0839 - roc-auc: 0.9962 - pr-auc: 0.8899 - val_loss: 0.1777 - val_roc-auc: 0.9220 - val_pr-auc: 0.4205\n",
      "Epoch 3/4\n",
      "3319/3319 [==============================] - 554s 167ms/step - loss: 0.0568 - roc-auc: 0.9981 - pr-auc: 0.9495 - val_loss: 0.1958 - val_roc-auc: 0.9098 - val_pr-auc: 0.4949\n",
      "Epoch 4/4\n",
      "3319/3319 [==============================] - 561s 169ms/step - loss: 0.0406 - roc-auc: 0.9992 - pr-auc: 0.9783 - val_loss: 0.1702 - val_roc-auc: 0.9341 - val_pr-auc: 0.6050\n"
     ]
    }
   ],
   "source": [
    "print_fn(f\"Train steps:      {tr_steps}\")\n",
    "print_fn(f\"Validation steps: {vl_steps}\")\n",
    "\n",
    "history = model.fit(x=train_data,\n",
    "                    validation_data=val_data,\n",
    "                    steps_per_epoch=tr_steps,\n",
    "                    validation_steps=vl_steps,\n",
    "                    class_weight=class_weight,\n",
    "                    epochs=initial_epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc = history.history['pr-auc']\n",
    "# val_acc = history.history['val_pr-auc']\n",
    "\n",
    "# loss = history.history['loss']\n",
    "# val_loss = history.history['val_loss']\n",
    "\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# plt.subplot(2, 1, 1)\n",
    "# plt.plot(acc, label='Training Accuracy')\n",
    "# plt.plot(val_acc, label='Validation Accuracy')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.ylim([min(plt.ylim()),1])\n",
    "# plt.title('Training and Validation Accuracy')\n",
    "\n",
    "# plt.subplot(2, 1, 2)\n",
    "# plt.plot(loss, label='Training Loss')\n",
    "# plt.plot(val_loss, label='Validation Loss')\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.ylabel('Cross Entropy')\n",
    "# plt.ylim([0,1.0])\n",
    "# plt.title('Training and Validation Loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_img_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Base model.\n",
      "trainable_weights: 154\n",
      "non_trainable_weights: 80\n",
      "layers: 133\n",
      "output_shape: (None, 2048)\n",
      "trainable_variables: 154\n",
      "\n",
      "Full model.\n",
      "trainable_weights: 174\n",
      "non_trainable_weights: 86\n",
      "layers: 17\n",
      "output_shape: (None, 1)\n",
      "trainable_variables: 174\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBase model.\")\n",
    "print(\"trainable_weights:\", len(base_img_model.trainable_weights))\n",
    "print(\"non_trainable_weights:\", len(base_img_model.non_trainable_weights))\n",
    "print(\"layers:\", len(base_img_model.layers))\n",
    "print(\"output_shape:\", base_img_model.output_shape)\n",
    "print(\"trainable_variables:\", len(base_img_model.trainable_variables))\n",
    "\n",
    "print(\"\\nFull model.\")\n",
    "print(\"trainable_weights:\", len(model.trainable_weights))\n",
    "print(\"non_trainable_weights:\", len(model.non_trainable_weights))\n",
    "print(\"layers:\", len(model.layers))\n",
    "print(\"output_shape:\", model.output_shape)\n",
    "print(\"trainable_variables:\", len(model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers in the base model:  133\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look to see how many layers are in the base model\n",
    "print(\"Number of layers in the base model: \", len(base_img_model.layers))\n",
    "\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 100\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_img_model.layers[:fine_tune_at]:\n",
    "    layer.trainable =  False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Base model.\n",
      "trainable_weights: 39\n",
      "non_trainable_weights: 195\n",
      "layers: 133\n",
      "output_shape: (None, 2048)\n",
      "trainable_variables: 39\n",
      "\n",
      "Full model.\n",
      "trainable_weights: 59\n",
      "non_trainable_weights: 201\n",
      "layers: 17\n",
      "output_shape: (None, 1)\n",
      "trainable_variables: 59\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBase model.\")\n",
    "print(\"trainable_weights:\", len(base_img_model.trainable_weights))\n",
    "print(\"non_trainable_weights:\", len(base_img_model.non_trainable_weights))\n",
    "print(\"layers:\", len(base_img_model.layers))\n",
    "print(\"output_shape:\", base_img_model.output_shape)\n",
    "print(\"trainable_variables:\", len(base_img_model.trainable_variables))\n",
    "\n",
    "print(\"\\nFull model.\")\n",
    "print(\"trainable_weights:\", len(model.trainable_weights))\n",
    "print(\"non_trainable_weights:\", len(model.non_trainable_weights))\n",
    "print(\"layers:\", len(model.layers))\n",
    "print(\"output_shape:\", model.output_shape)\n",
    "print(\"trainable_variables:\", len(model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "#               optimizer = tf.keras.optimizers.RMSprop(lr=base_learning_rate/10),\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "loss = losses.BinaryCrossentropy()\n",
    "# optimizer = optimizers.SGD(learning_rate=learning_rate/10, momentum=0.9, nesterov=True)\n",
    "optimizer = optimizers.Adam(learning_rate=learning_rate/10)\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/8\n",
      "3319/3319 [==============================] - 488s 142ms/step - loss: 0.0380 - roc-auc: 0.9887 - pr-auc: 0.8860 - val_loss: 0.1670 - val_roc-auc: 0.9305 - val_pr-auc: 0.5070\n",
      "Epoch 5/8\n",
      "3319/3319 [==============================] - 468s 141ms/step - loss: 0.0366 - roc-auc: 0.9987 - pr-auc: 0.9558 - val_loss: 0.1528 - val_roc-auc: 0.9339 - val_pr-auc: 0.5599\n",
      "Epoch 6/8\n",
      "3319/3319 [==============================] - 474s 143ms/step - loss: 0.0312 - roc-auc: 0.9993 - pr-auc: 0.9798 - val_loss: 0.1542 - val_roc-auc: 0.9325 - val_pr-auc: 0.5731\n",
      "Epoch 7/8\n",
      "3319/3319 [==============================] - 469s 141ms/step - loss: 0.0336 - roc-auc: 0.9991 - pr-auc: 0.9784 - val_loss: 0.1605 - val_roc-auc: 0.9308 - val_pr-auc: 0.5971\n",
      "Epoch 8/8\n",
      "3319/3319 [==============================] - 469s 141ms/step - loss: 0.0345 - roc-auc: 0.9989 - pr-auc: 0.9697 - val_loss: 0.1735 - val_roc-auc: 0.9313 - val_pr-auc: 0.5608\n"
     ]
    }
   ],
   "source": [
    "# fine_tune_epochs = 10\n",
    "fine_tune_epochs = 4\n",
    "total_epochs =  initial_epochs + fine_tune_epochs\n",
    "\n",
    "# history_fine = model.fit(train_dataset,\n",
    "#                          epochs=total_epochs,\n",
    "#                          initial_epoch=history.epoch[-1],\n",
    "#                          validation_data=validation_dataset)\n",
    "\n",
    "history_fine = model.fit(x=train_data,\n",
    "                    validation_data=val_data,\n",
    "                    steps_per_epoch=tr_steps,\n",
    "                    validation_steps=vl_steps,\n",
    "                    class_weight=class_weight,\n",
    "                    epochs=total_epochs,\n",
    "                    initial_epoch=history.epoch[-1],\n",
    "                    verbose=1,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc += history_fine.history['accuracy']\n",
    "# val_acc += history_fine.history['val_accuracy']\n",
    "\n",
    "# loss += history_fine.history['loss']\n",
    "# val_loss += history_fine.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(8, 8))\n",
    "# plt.subplot(2, 1, 1)\n",
    "# plt.plot(acc, label='Training Accuracy')\n",
    "# plt.plot(val_acc, label='Validation Accuracy')\n",
    "# plt.ylim([0.8, 1])\n",
    "# plt.plot([initial_epochs-1, initial_epochs-1], plt.ylim(), label='Start Fine Tuning')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.title('Training and Validation Accuracy')\n",
    "\n",
    "# plt.subplot(2, 1, 2)\n",
    "# plt.plot(loss, label='Training Loss')\n",
    "# plt.plot(val_loss, label='Validation Loss')\n",
    "# plt.ylim([0, 1.0])\n",
    "# plt.plot([initial_epochs-1, initial_epochs-1], plt.ylim(), label='Start Fine Tuning')\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.title('Training and Validation Loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain = \"imagenet\"\n",
    "pooling = \"avg\"\n",
    "image_shape = (cfg.IMAGE_SIZE, cfg.IMAGE_SIZE, 3)\n",
    "tile_input_tensor = tf.keras.Input(shape=image_shape, name=\"tile_image\")\n",
    "mm = tf.keras.applications.Xception(\n",
    "    include_top=False,\n",
    "    weights=pretrain,\n",
    "    input_shape=None,\n",
    "    input_tensor=None,\n",
    "    pooling=pooling)\n",
    "\n",
    "x = mm(tile_input_tensor, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "model = tf.keras.Model(tile_input_tensor, outputs)\n",
    "\n",
    "import ipdb; ipdb.set_trace()\n",
    "# Layers & models have three weight attributes:\n",
    "# weights: list of all weights variables of the layer.\n",
    "# trainable_weights: list of those that are meant to be updated (via gradient descent) to minimize the loss during training.\n",
    "# non_trainable_weights: list of those that aren't meant to be trained. Typically they are updated by the model during the forward pass.\n",
    "# In general, all weights are trainable weights. The only built-in layer that has non-trainable weights is the BatchNormalization layer. It uses non-trainable weights to keep track of the mean and variance of its inputs during training.\n",
    "print(\"trainable_weights:\", len(mm.trainable_weights))\n",
    "print(\"non_trainable_weights:\", len(mm.non_trainable_weights))\n",
    "print(\"layers:\", len(mm.layers))\n",
    "print(\"output shape:\", mm.output_shape)\n",
    "mm.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils for transfer learing with Keras\n",
    "def print_trainable_layers(model, print_all=False):\n",
    "    \"\"\" Print the trainable state of layers. \"\"\"\n",
    "    print('Trainable layers:')\n",
    "    for layer in model.layers:\n",
    "        if layer.trainable:\n",
    "            print(layer.name, layer.trainable)\n",
    "        if not layer.trainable and print_all:\n",
    "            print(layer.name, layer.trainable)\n",
    "\n",
    "            \n",
    "def freeze_layers(model, freeze_up_to='all'):\n",
    "    \"\"\" Freeze up to layer freeze_up_to, including! \"\"\"\n",
    "    # freeze_layers = ['1', '2', '3', '4']\n",
    "    if freeze_up_to=='all':\n",
    "        for layer in model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    #for layer in model.layers:\n",
    "    #    if any([True for i in layers_ids if i in layer.name]):\n",
    "    #        layer.trainable = False\n",
    "    for layer in model.layers:\n",
    "        # if freeze_up_to.lower() != layer.name.lower():\n",
    "        if freeze_up_to.lower() not in layer.name.lower():\n",
    "            layer.trainable = False\n",
    "        else:\n",
    "            layer.trainable = False\n",
    "            break\n",
    "\n",
    "def pop_layers(model, keep_up_to):\n",
    "    # pop_layers = ['4', '5', 'outputs']\n",
    "    model_layers = model.layers\n",
    "    #for layer in model_layers[::-1]:\n",
    "    #    if any([True for i in layers_ids if i in layer.name]):\n",
    "    #        model.layers.pop()  \n",
    "    \n",
    "    for layer in model_layers[::-1]:\n",
    "        # if keep_up_to.lower() != layer.name.lower():\n",
    "        if keep_up_to.lower() not in layer.name.lower():\n",
    "            model.layers.pop()\n",
    "        else:\n",
    "           break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
