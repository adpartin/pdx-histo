Note! I haven't setup a working Makefile yet.

# Create the env
1. Run the conda_create.sh
   $ ./conda_create.sh

2. Activate conda env
   $ conda activate pdx

3. Insall the reaining packages with Makefile
   $ make dev-venv

# Activate the env
source ./venv/bin/activate

# ----------------------
# Put this into Makefile
# ----------------------
# Build tidy datasets
python scripts/build_tidy_df_all_samples.py
python scripts/build_tidy_df_partially_balanced.py

# Generate data splits
# (need to update the bash scripts as needed)
./scripts/split_new.bash

# Train
./scripts/baseline.bash 2
./scripts/multimodal.bash 2

# ----------------------
# Improve code
# ----------------------
# Group partition and stratification
# http://www.xavierdupre.fr/app/pandas_streaming/helpsphinx/pandas_streaming/df/connex_split.html

# Change input shape dimensions for fine-tuning with Keras
# https://www.pyimagesearch.com/2019/06/24/change-input-shape-dimensions-for-fine-tuning-with-keras/

# Working TFRecords and transfer learning for computer vision
# https://www.kaggle.com/learn/computer-vision
# https://www.kaggle.com/cdeotte/triple-stratified-kfold-with-tfrecords/
# https://www.kaggle.com/agentauers/incredible-tpus-finetune-effnetb0-b6-at-once
# https://www.kaggle.com/samusram/hpa-classifier-explainability-segmentation
